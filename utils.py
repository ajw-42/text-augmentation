# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nluuej7tVJVbgA7gltrdYramnWNUHWaz
"""

import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC

from nltk.tokenize import wordpunct_tokenize
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from gensim.models import Word2Vec

from laserembeddings import Laser

def tfidf_classifier(x_train, y_train, x_test, y_test):

  vectorizer = TfidfVectorizer()
  train_vectors = vectorizer.fit_transform(x_train)
  test_vectors = vectorizer.transform(x_test)

  classifier = SVC(random_state=0).fit(train_vectors, y_train)
  preds = classifier.predict(test_vectors)

  print(f'Accuracy score: {accuracy_score(preds, y_test).round(2)}')

def word2vec_classifier(x_train, y_train, x_test, y_test):
  x_train_tokenized = [wordpunct_tokenize(x) for x in x_train]
  x_test_tokenized = [wordpunct_tokenize(x) for x in x_test]

  w2v_model = Word2Vec(x_train_tokenized, min_count=1)

  train_vectors = []
  test_vectors = []

  for doc in x_train_tokenized:
    doc_words = [word for word in doc if word in w2v_model.wv.vocab]
    if len(doc_words) >= 1:
        train_vectors.append(np.mean(w2v_model[doc_words], axis=0))
    else:
        train_vectors.append(np.array([0] * 100))

  for doc in x_test_tokenized:
    doc_words = [word for word in doc if word in w2v_model.wv.vocab]
    if len(doc_words) >= 1:
        test_vectors.append(np.mean(w2v_model.wv[doc_words], axis=0))
    else:
        test_vectors.append(np.array([0] * 100))

  #quick check to be sure no mistakes
  if len(train_vectors) != len(y_train):
    print('no')
  if len(test_vectors) != len(y_test):
    print('no')

  classifier = SVC(random_state=0).fit(np.array(train_vectors), y_train)
  preds = classifier.predict(np.array(test_vectors))

  print(f'Accuracy score: {accuracy_score(preds, y_test).round(2)}')

def doc2vec_classifier(x_train, y_train, x_test, y_test):
  documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(x_train)]
  model = Doc2Vec(documents, vector_size=300, window=2, min_count=1, workers=4, epochs=20)

  train_vectors = [model.infer_vector(x) for x in x_train]
  test_vectors = [model.infer_vector(x) for x in x_test]

  classifier = SVC(random_state=0).fit(train_vectors, y_train)
  preds = classifier.predict(test_vectors)

  print(f'Accuracy score: {accuracy_score(preds, y_test).round(2)}')

def laser_classifier(x_train, y_train, x_test, y_test):
  laser = Laser()

  train_vectors = [laser.embed_sentences([text], lang='ar') for text in x_train]
  test_vectors = [laser.embed_sentences([text], lang='ar') for text in x_test]
  train_vectors = [np.concatenate(x) for x in train_vectors]
  test_vectors = [np.concatenate(x) for x in test_vectors]

  classifier = SVC(random_state=0).fit(train_vectors, y_train)
  preds = classifier.predict(test_vectors)

  print(f'Accuracy score: {accuracy_score(preds, y_test).round(2)}')